The problem discussed hence is moral or ethical: who should an automated vehicle save or kill if an unavoidable accident takes place. Even though the probability of such a dire situation occurring is small, it still exists. And if automated vehicles are to become a part of the human world, these moral dilemmas need to be solved. 
Let’s try and look at the problem from a technical as well as an ethical point of view. First, let’s explore the technical aspect. For a vehicle to be autonomous, it needs to be able to see and comprehend its surrounding. To accomplish that, today’s AVs rely on technologies like LiDar, integrated photonics, mapping, Machine Learning, and Artificial Intelligence. 

LiDar is a bigger and better version of a radar where instead of sending short pulses of RW or MW, it sends out pulses of narrow infrared laser in many directions instead of just one. This technique has a depth perception of a few centimeters. Note something interesting here: when this concept overlaps with those of integrated photonics and of interference that can be increased to a millimeter or even better, it may one day lead to a moveable laser beam. 
Mapping and detection prove detrimental when it comes to making decisions. Moreover, simulation and data collection on the part of the machine may prove to be valuable. For instance, some of the best human drivers are racers with their calm and split-second decision making as well as the ability to find the best path around the track. Learning from them and studying how they would react might help.

When looking for solutions we tend to steer towards the more complex solutions overlooking the precautionary measures. For example, a few of those can be: driving slower (if the car is behind a large vehicle) and maintaining a distance from commercial cargo vehicles like lorries or loaded trucks. Generally speaking, being more cautious and on an alert mode around vehicles that are larger than the self-driving car will prove helpful. And it is always advisable to stop if one is unsure. As observed, the collision of two vehicles of similar sizes leads to comparatively lesser damage as compared to when two drastically different sized vehicles. The addition of extra safety features will provide another layer of safety.

Furthermore, we are too focused on making the self-driving cars algorithmic rather than making them a little intuitive, or even better trying to find a balance between the two. Combining the above two as the technical as well the ethical aspect of the problem might take us closer to reaching a solution.
Morality is not constant. It varies across people, continents, countries, cultures, and so on. So, trying to come up with a global solution is just like launching a piece of one size fits all clothing; yes, it does fit several people but it leaves out others. Self-driving cars aim to make the roads safer because 90% of road accidents are due to human error. There will always be situations that have not been encountered before with a varied number of options and dilemmas, and we cannot program them all.
